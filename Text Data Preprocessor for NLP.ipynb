{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02fa9b7-2a06-4795-9495-e568c00c4e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee0cf9f7-b52c-4bb1-9f8c-8cbea2f51f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_tweet_data = pd.read_csv(r'D:\\Computer Science & Engineering\\Jupyter Notebook project\\Data Preprocessor for NLP using Python\\disaster_tweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f4edb7c-3600-461e-b951-e983feda05ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_tweet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c312b8db-ed88-42c3-a913-b28eec16b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e830d9f-bb6d-40e8-a289-77d45701e5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_tweet_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5c303-7f39-4bcb-aad4-f7d8b5d427ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in columns of  keyword or location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37e205fc-757b-45cd-8b62-e413219b764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_tweet_data_cleaned = disaster_tweet_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f21cac53-1d08-45dc-86c2-05c80e20ee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5080, 5)\n"
     ]
    }
   ],
   "source": [
    "print(disaster_tweet_data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7bbbd4f-04f8-4db5-bbe7-114f22d24e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_tweet_data_filled = disaster_tweet_data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96749ed7-67ea-428a-a198-f02419460ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca30be8-1646-439e-bd43-7ea714a0e3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_tweet_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646dd24a-9cdf-4746-99e8-fd6f3f8edf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3af3870-0396-4437-8b21-285f353e7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_tweet_data_cleaned = disaster_tweet_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79bc1818-b88a-4382-8180-06d548dfad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n"
     ]
    }
   ],
   "source": [
    "print(disaster_tweet_data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef460ec-3e51-4660-9f2a-1430603d20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf664b8c-9373-45b5-a1d4-f9d79c636278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lowercase\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1219b893-b97a-4a5e-8abb-01cba40d1454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "df['text'] = df['text'].str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "df['text'] = df['text'].str.replace(r'\\d+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b4ce060-d124-433e-ab1c-d78f45742d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "df['text'] = df['text'].str.split().str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37287e68-83a7-48d7-90ad-2ec522e388f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of stopwords\n",
    "stopwords = ['the', 'is', 'in', 'and', 'to', 'of', 'a', 'with', 'that', 'for', 'on', 'it']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37af84da-fb1d-4ccf-89fa-f41187d04312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "df['cleaned_text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42700be-bc4c-4270-af6d-b6a8866d5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original and cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0774bbe0-7401-4830-88b9-6673266a671f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>our deeds are reason this earthquake may allah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>all residents asked shelter place are being no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  our deeds are the reason of this earthquake ma...   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  all residents asked to shelter in place are be...   \n",
       "3  people receive wildfires evacuation orders in ...   \n",
       "4  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  our deeds are reason this earthquake may allah...  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  all residents asked shelter place are being no...  \n",
       "3  people receive wildfires evacuation orders cal...  \n",
       "4  just got sent this photo from ruby alaska as s...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79ad7b-3750-4ba2-914b-d719cc1de9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Step: Save the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f83acbcb-bfce-4ded-a53c-a6261f88d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_tweet_data_cleaned.to_csv(r'D:\\Computer Science & Engineering\\Jupyter Notebook project\\Data Preprocessor for NLP using Python\\disaster_tweet_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
